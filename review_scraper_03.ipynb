{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('QST_BA': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4c0bfb3f782de325ad29fca3e7f49701831d88115e99ca6c22d78d2885f399ff"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from re import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraper Tool\n",
    "def scrape():\n",
    "    temp = []\n",
    "    time = datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\")\n",
    "    contents =  driver.find_elements_by_class_name(\"tip-item\")\n",
    "    for content in contents:\n",
    "        temp.append(content.text + f\"\\n{time}\")\n",
    "    return temp[8:]"
   ]
  },
  {
   "source": [
    "# BJ's Data Collection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = \"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "# driver = webdriver.Chrome(PATH)\n",
    "# driver.get(\"https://www.groupon.com/deals/n-bjs-wholesale-club-memberships\") #BJ's\n",
    "# driver.maximize_window()\n",
    "\n",
    "# sleep(4)\n",
    "\n",
    "# all_reviews = driver.find_element_by_xpath(\"/html/body/section[2]/div/section/div/div[2]/div[2]/section/div/div/article/div[3]/div[2]/div[2]/a\")\n",
    "\n",
    "# all_reviews.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = []\n",
    "# for i in range(535): #535 Pages\n",
    "    \n",
    "#     for j in scrape():\n",
    "#         temp.append(j)\n",
    "#     next_button = driver.find_element_by_xpath(\"/html/body/div[*]/div[2]/div[5]/div[2]\")\n",
    "#     next_button.click()\n",
    "\n",
    "#     reviews_bj = pd.DataFrame(temp, columns= [\"full\"])\n",
    "\n",
    "#     sleep(3)\n",
    "\n",
    "# reviews = reviews_bj.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews[\"split\"] =reviews[\"full\"].str.split(\"\\n\")\n",
    "# reviews[\"length\"] = [len(i) for i in reviews.split]\n",
    "\n",
    "# # Not all reviews are the same. Some missing elements\n",
    "# reviews.length.value_counts()\n",
    "# reviews.loc[reviews.length == 5,\"split\"]#[4141]\n",
    "# reviews.loc[reviews.length == 6,\"split\"]#[600]\n",
    "# reviews.loc[reviews.length == 7,\"split\"]#[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews[\"title\"] = \"\"\n",
    "# reviews[\"subtitle\"] = \"\"\n",
    "# reviews[\"date_published\"] = \"\"\n",
    "# reviews[\"text\"] = \"\"\n",
    "# reviews[\"date_scraped\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # parsing out split to approriate column based on length\n",
    "\n",
    "# for i, split in enumerate(reviews.split):\n",
    "\n",
    "#     if reviews.length[i] == 7:\n",
    "#         reviews.loc[reviews.index == i,\"title\"] = split[1]\n",
    "#         reviews.loc[reviews.index == i,\"subtitle\"] = split[2]\n",
    "#         reviews.loc[reviews.index == i,\"date_published\"] = split[3]\n",
    "#         reviews.loc[reviews.index == i,\"text\"] = split[4]\n",
    "#         reviews.loc[reviews.index == i,\"date_scraped\"] =split[6]\n",
    "\n",
    "#     elif len(split) == 6:\n",
    "#         reviews.loc[reviews.index == i,\"title\"] = split[1]\n",
    "#         reviews.loc[reviews.index == i,\"subtitle\"] = split[2]\n",
    "#         reviews.loc[reviews.index == i,\"date_published\"] = split[3]\n",
    "#         reviews.loc[reviews.index == i,\"text\"] = \"None\"\n",
    "#         reviews.loc[reviews.index == i,\"date_scraped\"] =split[5]\n",
    "\n",
    "#     elif len(split) == 5:\n",
    "#         reviews.loc[reviews.index == i,\"title\"] = \"None\"\n",
    "#         reviews.loc[reviews.index == i,\"subtitle\"] = split[0]\n",
    "#         reviews.loc[reviews.index == i,\"date_published\"] = split[1]\n",
    "#         reviews.loc[reviews.index == i,\"text\"] = split[2]\n",
    "#         reviews.loc[reviews.index == i,\"date_scraped\"] =split[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Found an anomly with reviews with review 4661. Had no name but was a helpful reviewer\n",
    "\n",
    "# reviews.split[4661]\n",
    "# reviews.loc[reviews.index == 4661,\"title\"] = \"None\"+reviews.split[4661][0]\n",
    "# reviews.loc[reviews.index == 4661,\"subtitle\"] = reviews.split[4661][1]\n",
    "# reviews.loc[reviews.index == 4661,\"date_published\"] = reviews.split[4661][2]\n",
    "# reviews.loc[reviews.index == 4661,\"text\"] = reviews.split[4661][3]\n",
    "# reviews.loc[reviews.index == 4661,\"date_scraped\"] = reviews.split[4661][5]\n",
    "# reviews.loc[reviews.index == 4661,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Parsing out title and subtitle columns further\n",
    "\n",
    "# reviews[\"top_reviewer\"] = [1 if (\"TOP REVIEWER\" in i) else 0 for i in reviews.title]\n",
    "# reviews[\"helpful_reviewer\"] = [1 if (\"HELPFUL REVIEWER\" in i) else 0 for i in reviews.title]\n",
    "# reviews[\"rating\"] = [int(re.findall(r'\\d+',i)[0]) if len(re.findall(r'\\d+',i))>0 else 0 for i in reviews.subtitle]\n",
    "# reviews[\"name\"] = [re.split('TOP REVIEWER|HELPFUL REVIEWER',i)[0] for i in reviews.title]\n",
    "\n",
    "# reviews[\"review_count\"] = 0\n",
    "# for i, subtitle in enumerate(reviews.subtitle[:10]):\n",
    "#     num = re.findall(r'\\d+',subtitle)\n",
    "#     if len(num) > 0:\n",
    "#         if search (\"rating\", subtitle):\n",
    "#             reviews.loc[reviews.index == i,\"review_count\"] = int(num[1])\n",
    "#         else:\n",
    "#             reviews.loc[reviews.index == i,\"review_count\"] = int(num[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Formating date_published that are in a relative format (# days/hours ago)\n",
    "\n",
    "# for i, date in enumerate(reviews.date_published):\n",
    "    \n",
    "#     if \"ago\" in date:\n",
    "#         if \"day\" in date:\n",
    "#             scraped = datetime.strptime(reviews.date_scraped[i],\"%m/%d/%Y %H:%M:%S\").date()\n",
    "#             ago = timedelta(days = int(re.findall(r'\\d+',date)[0]))\n",
    "#             reviews.loc[reviews.index == i,\"date_published\"] = (scraped - ago).strftime(\"%m/%d/%Y\")\n",
    "#         else:\n",
    "#             reviews.loc[reviews.index == i,\"date_published\"] = reviews.date_scraped[i][:10]\n",
    "#     elif date != \"'\": \n",
    "#         reviews.loc[reviews.index == i,\"date_published\"] = datetime.strptime(reviews.date_published[i],\"%B %d, %Y\").date().strftime(\"%m/%d/%Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BJ's CSV\n",
    "# reviews.to_csv('Groupon_BJs_Raw.csv', index=False)\n",
    "# reviews[['name', 'text', 'rating', 'review_count','top_reviewer', 'helpful_reviewer','date_published','date_scraped']].to_csv('Groupon_BJs.csv', index=False)"
   ]
  },
  {
   "source": [
    "# Sam's Club Data Collection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = \"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "# driver = webdriver.Chrome(PATH)\n",
    "# # driver.get(\"https://www.groupon.com/deals/n-sams-club-membership-packages-7#tips\") #Sam's Club\n",
    "# driver.maximize_window()\n",
    "\n",
    "# sleep(4)\n",
    "\n",
    "# all_reviews = driver.find_element_by_xpath(\"/html/body/section[2]/div/section/div/div[2]/div[2]/section/div/div/article/div[3]/div[2]/div[2]/a\")\n",
    "# all_reviews.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = []\n",
    "# for i in range(2828): #2828\n",
    "    \n",
    "#     for j in scrape():\n",
    "#         temp.append(j)\n",
    "#     next_button = driver.find_element_by_xpath(\"/html/body/div[*]/div[2]/div[5]/div[2]\")\n",
    "#     next_button.click()\n",
    "\n",
    "#     reviews_sam = pd.DataFrame(temp, columns= [\"full\"])\n",
    "\n",
    "#     sleep(3)\n",
    "\n",
    "# reviews = reviews_sam.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews[\"split\"] =reviews[\"full\"].str.split(\"\\n\")\n",
    "# reviews[\"length\"] = [len(i) for i in reviews.split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Not all reviews are the same. Some missing elements\n",
    "# reviews.length.value_counts()\n",
    "# reviews.loc[reviews.length == 5,\"split\"]#[4141]\n",
    "# reviews.loc[reviews.length == 6,\"split\"]#[600]\n",
    "# reviews.loc[reviews.length == 7,\"split\"]#[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews[\"title\"] = \"\"\n",
    "# reviews[\"subtitle\"] = \"\"\n",
    "# reviews[\"date_published\"] = \"\"\n",
    "# reviews[\"text\"] = \"\"\n",
    "# reviews[\"date_scraped\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, split in enumerate(reviews.split):\n",
    "\n",
    "#     if len(split) == 7:\n",
    "#         reviews.loc[reviews.index == i,\"title\"] = split[1]\n",
    "#         reviews.loc[reviews.index == i,\"subtitle\"] = split[2]\n",
    "#         reviews.loc[reviews.index == i,\"date_published\"] = split[3]\n",
    "#         reviews.loc[reviews.index == i,\"text\"] = split[4]\n",
    "#         reviews.loc[reviews.index == i,\"date_scraped\"] =split[6]\n",
    "\n",
    "#     elif len(split) == 6:\n",
    "#         reviews.loc[reviews.index == i,\"title\"] = split[1]\n",
    "#         reviews.loc[reviews.index == i,\"subtitle\"] = split[2]\n",
    "#         reviews.loc[reviews.index == i,\"date_published\"] = split[3]\n",
    "#         reviews.loc[reviews.index == i,\"text\"] = \"None\"\n",
    "#         reviews.loc[reviews.index == i,\"date_scraped\"] =split[5]\n",
    "\n",
    "#     elif len(split) == 5:\n",
    "#         reviews.loc[reviews.index == i,\"title\"] = \"None\"\n",
    "#         reviews.loc[reviews.index == i,\"subtitle\"] = split[0]\n",
    "#         reviews.loc[reviews.index == i,\"date_published\"] = split[1]\n",
    "#         reviews.loc[reviews.index == i,\"text\"] = split[2]\n",
    "#         reviews.loc[reviews.index == i,\"date_scraped\"] =split[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checked reviews \n",
    "# reviews.loc[reviews.length == 5,]\n",
    "# reviews.loc[reviews.length == 6,]\n",
    "# reviews.loc[reviews.length == 7,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Found an anomly with reviews with length 6. Some have no rating but have text. Some have no text but ratings. Some have no text or ratings but are a TOP/HELPFUL Reviewer.\n",
    "\n",
    "# no_subtitle = reviews.index[reviews.subtitle.str.contains(\"rating|reviews\") == False].tolist()\n",
    "# no_title = reviews.index[reviews.title.str.contains(\"rating\")].tolist()\n",
    "\n",
    "# for i, split in enumerate(reviews.split):\n",
    "\n",
    "#     if len(split) == 6 and (i in no_subtitle):\n",
    "#         reviews.loc[reviews.index == i,\"title\"] = split[1]\n",
    "#         reviews.loc[reviews.index == i,\"subtitle\"] = \"None\"\n",
    "#         reviews.loc[reviews.index == i,\"date_published\"] = split[2]\n",
    "#         reviews.loc[reviews.index == i,\"text\"] = split[3]\n",
    "#         reviews.loc[reviews.index == i,\"date_scraped\"] =split[5]\n",
    "\n",
    "#     if len(split) == 6 and (i in no_title):\n",
    "#         reviews.loc[reviews.index == i,\"title\"] = \"None\" + split[0]\n",
    "#         reviews.loc[reviews.index == i,\"subtitle\"] = split[1]\n",
    "#         reviews.loc[reviews.index == i,\"date_published\"] = split[2]\n",
    "#         reviews.loc[reviews.index == i,\"text\"] = split[3]\n",
    "#         reviews.loc[reviews.index == i,\"date_scraped\"] = split[5]\n",
    "\n",
    "# # Check \n",
    "# # reviews.loc[reviews.length == 6,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Parsing out title and subtitle columns further\n",
    "\n",
    "# reviews[\"top_reviewer\"] = [1 if (\"TOP REVIEWER\" in i) else 0 for i in reviews.title]\n",
    "# reviews[\"helpful_reviewer\"] = [1 if (\"HELPFUL REVIEWER\" in i) else 0 for i in reviews.title]\n",
    "# reviews[\"rating\"] = [int(re.findall(r'\\d+',i)[0]) if len(re.findall(r'\\d+',i))>0 else 0 for i in reviews.subtitle]\n",
    "# reviews[\"name\"] = [re.split('TOP REVIEWER|HELPFUL REVIEWER',i)[0] for i in reviews.title]\n",
    "\n",
    "# reviews[\"review_count\"] = 0\n",
    "# for i, subtitle in enumerate(reviews.subtitle[:10]):\n",
    "#     num = re.findall(r'\\d+',subtitle)\n",
    "#     if len(num) > 0:\n",
    "#         if search (\"rating\", subtitle):\n",
    "#             reviews.loc[reviews.index == i,\"review_count\"] = int(num[1])\n",
    "#         else:\n",
    "#             reviews.loc[reviews.index == i,\"review_count\"] = int(num[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Formating date_published that are in a relative format (# days/hours ago)\n",
    "\n",
    "# for i, date in enumerate(reviews.date_published):\n",
    "    \n",
    "#     if \"ago\" in date:\n",
    "#         if \"day\" in date:\n",
    "#             scraped = datetime.strptime(reviews.date_scraped[i],\"%m/%d/%Y %H:%M:%S\").date()\n",
    "#             ago = timedelta(days = int(re.findall(r'\\d+',date)[0]))\n",
    "#             reviews.loc[reviews.index == i,\"date_published\"] = (scraped - ago).strftime(\"%m/%d/%Y\")\n",
    "#         else:\n",
    "#             reviews.loc[reviews.index == i,\"date_published\"] = reviews.date_scraped[i][:10]\n",
    "#     else: \n",
    "#         reviews.loc[reviews.index == i,\"date_published\"] = datetime.strptime(reviews.date_published[i],\"%B %d, %Y\").date().strftime(\"%m/%d/%Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Sam's Club CSV\n",
    "# reviews.to_csv('Groupon_SamsClub_Raw.csv', index=False)\n",
    "# reviews[['name', 'text', 'rating', 'review_count','top_reviewer', 'helpful_reviewer','date_published','date_scraped']].to_csv('Groupon_SamsClub.csv', index=False)"
   ]
  }
 ]
}