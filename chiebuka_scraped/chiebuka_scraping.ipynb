{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('gmap_scraper': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "df961a54aa5a02c215f46f08da8e0d998ca1359df7cdad4f6941d6daddef2474"
   }
  },
  "interpreter": {
   "hash": "df961a54aa5a02c215f46f08da8e0d998ca1359df7cdad4f6941d6daddef2474"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from re import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open('Sams', \"r\")\n",
    "lines = df.readlines()\n",
    "df.close()\n",
    "\n",
    "for index, line in enumerate(lines):\n",
    "      lines[index] = line.strip()\n",
    "\n",
    "urls = pd.DataFrame(lines, columns= [\"url\"])\n",
    "urls[\"main_index\"] = [i for i in range(len(urls.url))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, url in enumerate(urls.url):\n",
    "#     f= open(f\"Sams_url_{i}.txt\",\"w+\")\n",
    "#     f.write(url)\n",
    "#     f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(PATH)\n",
    "# driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(urls.loc[urls[\"main_index\"]==2,\"url\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_count(url_index):\n",
    "    driver.get(urls.loc[urls[\"main_index\"]==url_index,\"url\"].values[0])\n",
    "    sleep(6)\n",
    "    count = driver.find_element_by_xpath(\"/html/body/jsl/div[3]/div[9]/div[8]/div/div[1]/div/div/div[2]/div[1]/div[1]/div[2]/div/div[1]/span[1]/span/span[1]/span[2]/span[1]/button\").text.split(\" reviews\")[0]\n",
    "    print(f'python scraper.py --N {count} --i BJ_url_{url_index}.txt')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls.main_index:\n",
    "    review_count(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_count()"
   ]
  },
  {
   "source": [
    "# Debug"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n",
    "import re\n",
    "import logging\n",
    "import traceback\n",
    "\n",
    "GM_WEBPAGE = 'https://www.google.com/maps/'\n",
    "MAX_WAIT = 10\n",
    "MAX_RETRY = 5\n",
    "MAX_SCROLLS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " def __scroll():\n",
    "        scrollable_div = driver.find_element_by_css_selector('div.section-layout.section-scrollbox.cYB2Ge-oHo7ed') #cYB2Ge-ti6hGc\n",
    "        # scrollable_div = driver.find_element_by_class_name('section-layout section-scrollbox')\n",
    "        driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scrollable_div)\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        #document.getElementsByClassName('section-layout section-scrollbox')[0].scrollBy(0,document.getElementsByClassName('section-layout section-scrollbox')[0].scrollHeight)\n",
    "\n",
    "__scroll()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __expand_reviews():\n",
    "        # use XPath to load complete reviews\n",
    "        links = driver.find_elements_by_xpath('//button[@class=\\'section-expand-review blue-link\\']')\n",
    "        for l in links:\n",
    "            l.click()\n",
    "        time.sleep(12)\n",
    "\n",
    "__expand_reviews()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(offset):\n",
    "\n",
    "        # scroll to load reviews\n",
    "\n",
    "        # wait for other reviews to load (ajax)\n",
    "        time.sleep(14)\n",
    "\n",
    "        __scroll()\n",
    "\n",
    "\n",
    "        # expand review text\n",
    "        __expand_reviews()\n",
    "\n",
    "        # parse reviews\n",
    "        response = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        rblock = response.find_all('div', class_='section-review-content')\n",
    "        parsed_reviews = []\n",
    "        for index, review in enumerate(rblock):\n",
    "            if index >= offset:\n",
    "                parsed_reviews.append(__parse(review))\n",
    "                print(__parse(review))\n",
    "\n",
    "        return parsed_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util function to clean special characters\n",
    "def __filter_string(str):\n",
    "        strOut = str.replace('\\r', ' ').replace('\\n', ' ').replace('\\t', ' ')\n",
    "        return strOut\n",
    "\n",
    "def __parse(review):\n",
    "        \n",
    "        # get address here \n",
    "        \n",
    "        item = {}\n",
    "\n",
    "        id_review = review.findChild(\"div\")['data-review-id']\n",
    "        # id_review = review.find('button', class_='section-review-action-menu')['data-review-id'] #OLD\n",
    "        username = review.find('div', class_='ODSEW-ShBeI-title').find('span').text\n",
    "        # username = review.find('div', class_='section-review-title').find('span').text\n",
    "\n",
    "\n",
    "        try:\n",
    "            # review_text = __filter_string(review.find('span', class_='section-review-text').text)\n",
    "            review_text = __filter_string(review.find('span', class_='ODSEW-ShBeI-text').text)\n",
    "        except Exception as e:\n",
    "            review_text = None\n",
    "\n",
    "        rating = float(review.find('span', class_='ODSEW-ShBeI-H1e3jb')['aria-label'].split(' ')[1])\n",
    "        relative_date = review.find('span', class_='ODSEW-ShBeI-RgZmSc-date').text\n",
    "\n",
    "        # rating = float(review.find('span', class_='section-review-stars')['aria-label'].split(' ')[1])\n",
    "        # relative_date = review.find('span', class_='section-review-publish-date').text\n",
    "\n",
    "        try:\n",
    "            # n_reviews_photos = review.find('div', class_='section-review-subtitle').find_all('span')[1].text\n",
    "            n_reviews_photos = review.find('div', class_='ODSEW-ShBeI-subtitle').find_all('span')[1].text\n",
    "            \n",
    "            metadata = n_reviews_photos.split('\\xe3\\x83\\xbb')\n",
    "            if len(metadata) == 3:\n",
    "                n_photos = int(metadata[2].split(' ')[0].replace('.', ''))\n",
    "            else:\n",
    "                n_photos = 0\n",
    "\n",
    "            idx = len(metadata)\n",
    "            n_reviews = int(metadata[idx - 1].split(' ')[0].replace('.', ''))\n",
    "\n",
    "        except Exception as e:\n",
    "            n_reviews = 0\n",
    "            n_photos = 0\n",
    "\n",
    "        user_url = review.find('a')['href']\n",
    "\n",
    "        item['id_review'] = id_review\n",
    "        item['caption'] = review_text\n",
    "\n",
    "        # depends on language, which depends on geolocation defined by Google Maps\n",
    "        # custom mapping to transform into date shuold be implemented\n",
    "        item['relative_date'] = relative_date\n",
    "\n",
    "        # store datetime of scraping and apply further processing to calculate\n",
    "        # correct date as retrieval_date - time(relative_date)\n",
    "        item['retrieval_date'] = datetime.now()\n",
    "        item['rating'] = rating\n",
    "        item['username'] = username\n",
    "        item['n_review_user'] = n_reviews\n",
    "        item['n_photo_user'] = n_photos\n",
    "        item['url_user'] = user_url\n",
    "\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I loved my trip I got everything I wanted. I was in & out, no long lines, or waits. My only issue would be that they wouldn't let me use Samsung pay to get my reward points. Can't wait to go back.\n"
     ]
    }
   ],
   "source": [
    "# ODSEW-ShBeI NIyLF-haAclf gm2-body-2\n",
    "# section-review-content\n",
    "response = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "rblock = response.find_all('div', class_='ODSEW-ShBeI NIyLF-haAclf gm2-body-2')\n",
    "parsed_reviews = []\n",
    "for index, review in enumerate(rblock):\n",
    "    if index == 1: #>= offset\n",
    "        # print(review)\n",
    "        # print(review.find('span', class_='ODSEW-ShBeI-text').text)\n",
    "        print(__filter_string(review.find('span', class_='ODSEW-ShBeI-text').text))\n",
    "        # print(review.findChild(\"div\")['section-review-title'])\n",
    "        # print(review.find('div', class_='ODSEW-ShBeI-title').find('span').text)\n",
    "        # parsed_reviews.append(__parse(review))\n",
    "    #     # print(__parse(review))\n",
    "\n",
    "# ODSEW-ShBeI-content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'id_review': 'ChdDSUhNMG9nS0VJQ0FnSUNxZ1l1c2dnRRAB', 'caption': 'They had a plant sale this afternoon and my wife and I had a good time. We got quite a few things but ... We bought this tomato plant they had priced for 5.41 and they argued that it was 9.75. I wanted to take out a boss but she said it was …', 'relative_date': 'a week ago', 'retrieval_date': datetime.datetime(2021, 6, 16, 21, 9, 14, 551310), 'rating': 2.0, 'username': 'Harold Martinez', 'n_review_user': 0, 'n_photo_user': 0, 'url_user': 'https://www.google.com/maps/contrib/101799531237075069652/reviews?hl=en-US'}\n{'id_review': 'ChdDSUhNMG9nS0VJQ0FnSUNvbUl1RDB3RRAB', 'caption': \"I love Sam's...one of my favorite stores, always a deal to be had! 👌\", 'relative_date': 'a month ago', 'retrieval_date': datetime.datetime(2021, 6, 16, 21, 9, 14, 558306), 'rating': 5.0, 'username': 'C B', 'n_review_user': 0, 'n_photo_user': 0, 'url_user': 'https://www.google.com/maps/contrib/109995105564189992382/reviews?hl=en-US'}\n{'id_review': 'ChdDSUhNMG9nS0VJQ0FnSUNLbV9teXZ3RRAB', 'caption': 'Very clean, bright, and well-organized! Every staff person we spoke with was kind and helpful. Also very pleased with the sizes of some items like cakes and cookie trays. Not huge but smaller family friendly. Just need to compare prices carefully with all surrounding stores.', 'relative_date': 'a month ago', 'retrieval_date': datetime.datetime(2021, 6, 16, 21, 9, 14, 560304), 'rating': 4.0, 'username': 'Shelly Duggan', 'n_review_user': 0, 'n_photo_user': 0, 'url_user': 'https://www.google.com/maps/contrib/109248526045338194538/reviews?hl=en-US'}\n"
     ]
    }
   ],
   "source": [
    "# ODSEW-ShBeI NIyLF-haAclf gm2-body-2\n",
    "# section-review-content\n",
    "response = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "rblock = response.find_all('div', class_='ODSEW-ShBeI NIyLF-haAclf gm2-body-2')\n",
    "parsed_reviews = []\n",
    "for index, review in enumerate(rblock):\n",
    "    # if index == 1: #>= offset\n",
    "        # print(review)\n",
    "        parsed_reviews.append(__parse(review))\n",
    "        print(__parse(review))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsed_reviews[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LINKS HERE [<selenium.webdriver.remote.webelement.WebElement (session=\"62b1bd0238302bf4a993474a12bb5b97\", element=\"c151f367-561d-4d70-8005-0625129d62ac\")>]\n"
     ]
    }
   ],
   "source": [
    "def more_reviews():\n",
    "        # use XPath to load complete reviews\n",
    "        #allxGeDnJMl__text gm2-button-alt\n",
    "        #<button ved=\"1i:1,t:18519,e:0,p:kPkcYIz-Dtql-QaL1YawDw:1969\" jstcache=\"1202\" jsaction=\"pane.reviewChart.moreReviews\" class=\"gm2-button-alt jqnFjrOWMVU__button-blue\" jsan=\"7.gm2-button-alt,7.jqnFjrOWMVU__button-blue,0.ved,22.jsaction\">14 reviews</button>\n",
    "        #<button aria-label=\"14 reviews\" vet=\"3648\" jsaction=\"pane.rating.moreReviews\" jstcache=\"1010\" class=\"widget-pane-link\" jsan=\"7.widget-pane-link,0.aria-label,0.vet,0.jsaction\">14 reviews</button>\n",
    "    links = driver.find_elements_by_xpath('')\n",
    "    print('LINKS HERE', links)\n",
    "    for l in links:\n",
    "        l.click()\n",
    "    time.sleep(12)\n",
    "\n",
    "more_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __expand_reviews():\n",
    "        # use XPath to load complete reviews\n",
    "    links = driver.find_elements_by_xpath('//button[@class=\\'section-expand-review blue-link\\']')\n",
    "    for l in links:\n",
    "        l.click()\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "__expand_reviews()\n",
    "    # //*[@id=\"pane\"]/div/div[1]/div/div/div[2]/div[9]/div[19]/div/div[3]/div[3]/jsl/button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'7 Walmart Blvd, Hudson, NH 03051'"
      ]
     },
     "metadata": {},
     "execution_count": 208
    }
   ],
   "source": [
    "#   https://www.google.com/maps/place/Sam's+Club/@42.7265388,-71.4287465,17z/data=!3m1!4b1!4m5!3m4!1s0x89e3b104e3ab41af:0x774c987611771084!8m2!3d42.7265388!4d-71.4265578\n",
    "  \n",
    "def get_address(url):\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "    # resp = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # address = __get_address(resp)\n",
    "    address = driver.find_element_by_xpath('//*[@id=\"pane\"]/div/div[1]/div/div/div[9]/div[1]/button/div[1]/div[2]/div[1]').text\n",
    "        \n",
    "    return address\n",
    "\n",
    "\n",
    "    # QSFF4-text gm2-body-2\n",
    "\n",
    "\n",
    "get_address(\"https://www.google.com/maps/place/Sam's+Club/@42.7265388,-71.4287465,17z/data=!3m1!4b1!4m5!3m4!1s0x89e3b104e3ab41af:0x774c987611771084!8m2!3d42.7265388!4d-71.4265578\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'7 Walmart Blvd, Hudson, NH 03051'"
      ]
     },
     "metadata": {},
     "execution_count": 206
    }
   ],
   "source": [
    "# driver.find_element_by_class_name(\"QSFF4-text gm2-body-2\")\n",
    "driver.find_element_by_xpath('//*[@id=\"pane\"]/div/div[1]/div/div/div[9]/div[1]/button/div[1]/div[2]/div[1]').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_address(resp):\n",
    "        # use XPath to load complete reviews\n",
    "        \n",
    "        # button = self.driver.find_elements_by_xpath('/button[@class=\\'class=\"iRxY3GoUYUY__button gm2-hairline-border section-action-chip-button\"\\']')\n",
    "        # button.click()\n",
    "        # time.sleep(2)\n",
    "        #address = resp.find(\"div\",class_=\"ugiz4pqJLAG__root ugiz4pqJLAG__one-line-text ugiz4pqJLAG__dense ugiz4pqJLAG__metadata-shown-on-hover-only ugiz4pqJLAG__clickable'\").text\n",
    "        address = driver.find_element_by_xpath('//*[@id=\"pane\"]/div/div[1]/div/div/div[9]/div[1]/button/div[1]/div[2]/div[1]').text\n",
    "        return address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(self, offset):\n",
    "\n",
    "        # scroll to load reviews\n",
    "\n",
    "        # wait for other reviews to load (ajax)\n",
    "        time.sleep(14)\n",
    "\n",
    "        self.__scroll()\n",
    "\n",
    "\n",
    "        # expand review text\n",
    "        self.__expand_reviews()\n",
    "\n",
    "        # parse reviews\n",
    "        response = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "        rblock = response.find_all('div', class_='ODSEW-ShBeI NIyLF-haAclf gm2-body-2')\n",
    "        parsed_reviews = []\n",
    "        for index, review in enumerate(rblock):\n",
    "            if index >= offset:\n",
    "                parsed_reviews.append(self.__parse(review))\n",
    "                print(self.__parse(review))\n",
    "\n",
    "        return parsed_reviews"
   ]
  }
 ]
}